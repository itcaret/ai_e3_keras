## 3.2 機械学習への適用

これまでに見てきたとおり画像データを水平（垂直）移動したり、回転や拡大（縮小）、カラー変更したりすることで既存の画像データにノイズを加える方法を学びました。ここからは機械学習時にデータ拡張を導入して、モデルを訓練する様子をみていきましょう。


## 3.3 Kerasによるデータ拡張

ImageDataGeneratorクラスを使えば画像データを拡張できることを学びました。ここではImageDataGeneratorクラスを活用してKerasのCNNプログラムを作成してみましょう。

まずはImageDataGeneratorクラスのflowメソッドを活用するシンプルな方法を見てみます。その次にKerasのモデル（Model）に用意されているfit_generatorメソッドを使って、ImageDataGeneratorクラスでの画像生成を自動で組み込む方法を取り上げます。それからImageDataGeneratorクラスのflow_from_directoryを使って指定したフォルダ上の画像データを自動でロードする方法を紹介します。

1. flowメソッドによるデータ拡張
1. fit_generatorメソッドによるモデルへの統合
1. flow_from_directoryメソッドによるフォルダからのロード

### 1. flowメソッドによるデータ拡張

ImageDataGeneratorクラスのflowメソッドを使えばバッチサイズを指定して、画像データを生成できます。


```python
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from image_utils import load_images

x_train, x_test, y_train, y_test = load_images("dirA", "dirB")

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

model = Sequential()
model.add(Conv2D(128, kernel_size=(3, 3),
                    input_shape=(60, 90, 3), activation='relu'))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy,
           optimizer=keras.optimizers.Adadelta(),
           metrics=['accuracy'])

datagen = ImageDataGenerator(width_shift_range=0.3,
                             rotation_range=30,
                             zoom_range=0.3,
                             horizontal_flip=True,
                             vertical_flip=True)

for e in range(20):
    print('Epoch', e)
    batches = 0
    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
        history = model.fit(x_batch, y_batch,
                            validation_data=(x_test, y_test), epochs=1)
        batches += 1
        if batches >= len(x_train) / 32:
            break
```

> この方法はImageDataGeneratorの挙動を確認するために取り上げています。実際には次に紹介するfit_generatorメソッドを活用すると良いでしょう。

プログラムを実行すると次のような結果を確認できるでしょう。

```
Epoch 0
Train on 32 samples, validate on 399 samples
Epoch 1/1
32/32 2s - loss: 0.6806 - acc: 0.5312 - val_loss: 1.5479 - val_acc: 0.5338
Train on 32 samples, validate on 399 samples
・・・省略
Epoch 1/1
32/32 0s - loss: 0.3814 - acc: 0.8438 - val_loss: 0.4264 - val_acc: 0.7895
Train on 32 samples, validate on 399 samples
Epoch 1/1
32/32 0s - loss: 0.3214 - acc: 0.9062 - val_loss: 0.3981 - val_acc: 0.8195
Train on 10 samples, validate on 399 samples
Epoch 1/1
10/10 0s - loss: 0.4946 - acc: 0.9000 - val_loss: 0.4230 - val_acc: 0.8471
```

> 繰り返しmodel.fitメソッドを呼び出しているため、学習結果の出力を繰り返すことになります。

このサンプルプログラムではflowメソッドによって生成された画像データを使って訓練を行います。20回のエポックの中で新しい画像データを生成しながら、モデルに対して繰り返しfitメソッドを呼ぶことで学習していきます。

```python
for e in range(20):
    print('Epoch', e)
    batches = 0
    for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
        history = model.fit(x_batch, y_batch,
                            validation_data=(x_test, y_test), epochs=1)
        batches += 1
        if batches >= len(x_train) / 32:
            break
```

1回のエポックの中で画像生成時のバッチサイズに32を指定しています。

```python
for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):
```

訓練データ（x_train, y_train）の中から32件のデータが選択されて、新たな画像が生成されます。生成された画像を使ってモデルの学習を進めています。

```python
history = model.fit(x_batch, y_batch, validation_data=(x_test, y_test), epochs=1)
```

if文の条件についても補足しておきましょう。訓練データが1000件の場合、len(x_train) / 32 は 31.25となります。つまり画像データの生成（内側のfor文）を32回繰り返すると1回のエポックが終了します。

このようにして用意した画像データを拡張しながら、モデルの学習を進めることができます。

<div style="page-break-before:always"></div>

### 2. fit_generatorメソッドによるモデルへの統合

Kerasのモデル（Sequentialクラス）にはImageDataGeneratorを使った訓練をサポートするfit_generatorメソッドが提供されています。使い方を確認しておきましょう。

```python
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator
from image_utils import load_images

x_train, x_test, y_train, y_test = load_images("dirA", "dirB")

x_train = x_train.astype('float32')
x_test = x_test.astype('float32')
x_train /= 255
x_test /= 255

model = Sequential()
model.add(Conv2D(128, kernel_size=(3, 3),
                    input_shape=(60, 90, 3), activation='relu'))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy,
           optimizer=keras.optimizers.Adadelta(),
           metrics=['accuracy'])

datagen = ImageDataGenerator(width_shift_range=0.3,
                             rotation_range=30,
                             zoom_range=0.3,
                             horizontal_flip=True,
                             vertical_flip=True)


history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train) / 32, epochs=100,
                    validation_data=(x_test, y_test))
```

> 上記のプログラムは生成した画像データによる学習を繰り返すためにエポック数に100を指定しています。

プログラムを実行すると次のような結果を確認できるでしょう。

```
・・・省略
Epoch 97/100
38/37 3s - loss: 0.3330 - acc: 0.8551 - val_loss: 0.3934 - val_acc: 0.8446
Epoch 98/100
38/37 3s - loss: 0.3372 - acc: 0.8436 - val_loss: 0.3601 - val_acc: 0.8571
Epoch 99/100
38/37 3s - loss: 0.3218 - acc: 0.8427 - val_loss: 0.3932 - val_acc: 0.8371
Epoch 100/100
38/37 3s - loss: 0.3377 - acc: 0.8533 - val_loss: 0.3877 - val_acc: 0.8271
```

訓練データの正答率（acc）、テストデータの正答率ともに83%程度まで上昇しています。

正答率をグラフ化してみましょう。

```python
import matplotlib.pyplot as plt

plt.ylim(0, 1)
plt.plot(history.history['acc'], label="acc")
plt.plot(history.history['val_acc'], label="val_acc")
plt.legend()

plt.show()
```

<img src="img/05_glaph.png" width="300px">

以前の学習と比べて、過学習の傾向も解消されているのがわかります。

プログラムの詳細を見てみましょう。

```python
history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),
                    steps_per_epoch=len(x_train) / 32, epochs=100,
                    validation_data=(x_test, y_test))
```

fit_generatorメソッドの第1引数にはflowメソッドの戻り値（イテレータ）を指定します。引数steps_per_epochには、1回のエポック内でジェネレータ（ImageDataGenerator）から生成されるサンプル (サンプルのバッチ) の総数を意味します。一般的には訓練データのユニークなサンプル数をバッチサイズで割った値（訓練データが1000件の場合、1000/32=32）を指定します。

<div style="page-break-before:always"></div>

### 3. flow_from_directoryメソッドによるフォルダからのロード

これまでに画像データ拡張の実践方法について学びました。ImageDataGeneratorクラスにはフォルダ上の画像データをロードするユーティリティメソッド（flow_from_directory）が用意されています。


```python
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing.image import ImageDataGenerator

model = Sequential()
model.add(Conv2D(128, kernel_size=(3, 3),
                    input_shape=(60, 90, 3), activation='relu'))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss=keras.losses.binary_crossentropy,
           optimizer=keras.optimizers.Adadelta(),
           metrics=['accuracy'])

train_datagen = ImageDataGenerator(rescale=1.0/255,
                                   width_shift_range=0.3,
                                   rotation_range=30,
                                   zoom_range=0.3,
                                   horizontal_flip=True,
                                   vertical_flip=True)

train_generator = train_datagen.flow_from_directory('data60x90/train',
                                                    target_size=(60, 90),
                                                    batch_size=32,
                                                    class_mode='binary')

test_datagen = ImageDataGenerator(rescale=1.0/255)

test_generator = test_datagen.flow_from_directory('data60x90/test',
                                                        target_size=(60, 90),
                                                        batch_size=32,
                                                        class_mode='binary')

history = model.fit_generator(train_generator,
                    validation_data=test_generator,
                    steps_per_epoch=train_generator.samples / 32,
                    validation_steps=test_generator.samples / 32,
                    epochs=100)
```

> プログラムの実行結果は1つ前の結果と同様です。

flow_from_directoryメソッドの使い方を確認しておきましょう。

```python
train_generator = train_datagen.flow_from_directory('data60x90/train',
                                                    target_size=(60, 90),
                                                    batch_size=32,
                                                    class_mode='binary')
```

flow_from_directoryメソッドの第1引数には訓練データのパスを指定します。このときファイルシステム上において、次のような構成で訓練データが準備されている必要があります。

+ data60x90/train
    + CLASS_A
      + 001.jpg
      + 002.jpg
      + ...
    + CLASS_B
      + 001.jpg
      + 002.jpg
      + ...
    + CLASS_C
      + 001.jpg
      + 002.jpg
      + ...

つまり第1引数で指定したフォルダには、分類したいクラスごとにサブフォルダを準備しておく必要があります。それからサブフォルダの中にはPNGかJPG形式の画像を含む必要があります。これはテストデータについても同様です。

> フォルダ名やファイル名任意です。

その他の引数についても確認しておきましょう。target_size=(60, 90)を指定することで画像ファイルのロード時にファイルサイズをリサイズすることができます。指定しない場合のデフォルトは(256, 256)になります。

> 引数にcolor_mode="grayscale"を指定すると1チャネル（グレースケール）で読み込むこともできます。省略した場合のデフォルトはcolor_mode="rgb"となり、3チャネル（RGBチャネル）でロードされます。

次に引数batch_size=32はこれまでと同様にバッチサイズを指定しています。省略した場合のデフォルトも32です。

さいごに引数class_mode='binary'によって二値分類を指定しています。これによって自動的に1次元の二値ラベル（[0]か[1]）が生成されます。また多クラス分類の場合はclass_mode="categorical"を指定します。

<div style="page-break-before:always"></div>

また今回のサンプルプログラムではテストデータも同様にflow_from_directoryメソッドでロードしています。

```python
test_datagen = ImageDataGenerator(rescale=1.0/255)

test_generator = test_datagen.flow_from_directory('data60x90/test',
                                                        target_size=(60, 90),
                                                        batch_size=32,
                                                        class_mode='binary')
```

テストデータにはデータ拡張は行いませんのでImageDataGeneratorの引数にrescale=1.0/255のみ指定しています。これは画像データの各ピクセルの値を0〜1の値に置き換えています。


モデルのfit_generatorメソッドには、訓練データとテストデータ用の2つのジェネレータを指定します。

```python
history = model.fit_generator(train_generator,
                    validation_data=test_generator,
                    steps_per_epoch=train_generator.samples / 32,
                    validation_steps=test_generator.samples / 32,
                    epochs=100)
```

引数validation_stepsは、各エポックの終わりに検証用ジェネレータから使用するステップ数です。一般的にはテストデータのユニークなサンプル数をバッチサイズで割った値を指定します。
